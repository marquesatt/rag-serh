import os
import json
import uuid
from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from dotenv import load_dotenv
from typing import Optional
from vertexai.generative_models import (
    SafetySetting, HarmCategory, HarmBlockThreshold,
    Content, Part
)

load_dotenv()

PROJECT_ID = os.getenv("PROJECT_ID", "serhrag")
LOCATION = os.getenv("LOCATION", "europe-west4")
PORT = int(os.getenv("PORT", 8000))

# Configura credenciais do Google Cloud de forma segura
def setup_google_credentials():
    """Setup Google Cloud credentials usando vari√°vel de ambiente"""
    import tempfile
    
    # 1. Tenta usar vari√°vel de ambiente (produ√ß√£o e desenvolvimento)
    creds_json = os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON")
    if creds_json:
        try:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                f.write(creds_json)
                temp_creds_path = f.name
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = temp_creds_path
            print(f"‚úì Credenciais carregadas da vari√°vel de ambiente")
            return
        except Exception as e:
            print(f"‚úó Erro ao processar GOOGLE_APPLICATION_CREDENTIALS_JSON: {e}")
    
    # 2. Tenta arquivo local como fallback (desenvolvimento)
    import glob
    json_files = glob.glob("./serhrag*.json")
    if json_files:
        local_creds = json_files[0]
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = local_creds
        print(f"‚úì Credenciais carregadas do arquivo local: {local_creds}")
        return
    
    print("‚úó Nenhuma credencial encontrada")
    
    # Tenta arquivo local (desenvolvimento)
    local_creds = "./serhrag-d481c39ed083.json"
    if os.path.exists(local_creds):
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = local_creds
        print(f"‚úì Credenciais carregadas do arquivo local")
        return True
    
    print("‚úó Nenhuma credencial encontrada")
    print("   Para Railway: configure GOOGLE_CREDENTIALS_JSON nas vari√°veis de ambiente")
    print("   Para desenvolvimento local: adicione serhrag-d481c39ed083.json")
    return False

setup_google_credentials()

corpus = None
model = None


def init_vertex_ai():
    global corpus, model
    try:
        # imports locais para evitar conflitos
        import vertexai
        from vertexai import rag
        from vertexai.generative_models import GenerativeModel, Tool
        
        # autentica com google cloud
        print(f"Inicializando Vertex AI com PROJECT_ID={PROJECT_ID}, LOCATION={LOCATION}")
        vertexai.init(project=PROJECT_ID, location=LOCATION)
        print(f"‚úì Vertex AI inicializado")
        
        # carrega corpus
        print(f"Listando corpora dispon√≠veis...")
        corpora = list(rag.list_corpora())
        print(f"Corpora encontrados: {len(corpora)}")
        for corpus_item in corpora:
            print(f"  - {corpus_item.display_name} (ID: {corpus_item.name})")
        
        if corpora:
            corpus = corpora[0]
            print(f"‚úì Corpus carregado: {corpus.display_name}")
            
            # configura rag retrieval
            config = rag.RagRetrievalConfig(
                top_k=3,
                filter=rag.Filter(vector_distance_threshold=0.5),
            )
            
            tool = Tool.from_retrieval(
                retrieval=rag.Retrieval(
                    source=rag.VertexRagStore(
                        rag_resources=[rag.RagResource(rag_corpus=corpus.name)],
                        rag_retrieval_config=config,
                    ),
                )
            )
            
            # inicializa modelo
            model = GenerativeModel(
                model_name="gemini-2.0-flash",
                tools=[tool],
                system_instruction="""VOC√ä √â UM ASSISTENTE ESPECIALIZADO DE RECURSOS HUMANOS DO SERH
                
Voc√™ √© um chatbot chamado SERHChat. Seu prop√≥sito √© auxiliar colaboradores da Justi√ßa Federal com informa√ß√µes sobre o SERH (Sistema Eletr√¥nico de Recursos Humanos).

Voc√™ √© um assistente amig√°vel, profissional e confi√°vel. 

=== COMO VOC√ä FUNCIONA (IMPORTANTE) ===
N√ÉO mencione:
- "Documentos" 
- "Consultar registros"
- "Segundo os dados"
- "Baseado em informa√ß√µes"
- "RAG" ou qualquer sistema t√©cnico
- "Vou procurar"
- Qualquer refer√™ncia a que voc√™ est√° consultando fontes

Ao inv√©s disso, responda como se o conhecimento fosse seu conhecimento natural e integrado. Exemplo:
‚ùå ERRADO: "Segundo o documento, os times s√£o..."
‚úÖ CORRETO: "Os times do SERH s√£o: RED (liderado por Itamar), YELLOW (Seiji), BLUE (liderado por F√°bio) e ORANGE (Daniel)"

=== PRINC√çPIOS DE RESPOSTA ===

1. NATURALIDADE
   - Fale como um colega experiente, n√£o como um bot
   - Use tom conversacional mas profissional
   - Seja conciso mas completo

2. **NUNCA DIGA QUE N√ÉO SABE (CR√çTICO)**
   - ‚ùå NUNCA responda: "N√£o tenho essa informa√ß√£o", "Essa informa√ß√£o n√£o est√° dispon√≠vel", "N√£o sei"
   - ‚ùå NUNCA use frases como: "Essa informa√ß√£o n√£o faz parte do meu conhecimento"
   - ‚úÖ SEMPRE tente encontrar a resposta:
     a) Primeiro: Use a ferramenta de busca no corpus (RAG) para procurar informa√ß√µes relacionadas
     b) Segundo: Se encontrar informa√ß√£o parcial, expanda usando racioc√≠nio l√≥gico
     c) Terceiro: Se mesmo assim n√£o tiver certeza, fa√ßa perguntas clarificadoras ao usu√°rio
   - Exemplo correto: "Entendi sua pergunta. Deixa eu pensar... [racioc√≠nio]. Voc√™ quer saber mais sobre [clarifica√ß√£o]?"

3. RACIOC√çNIO E DEDU√á√ÉO
   - Se a pergunta usa palavras diferentes de um t√≥pico que voc√™ conhece, reconhe√ßa a equival√™ncia
   - Use l√≥gica para conectar conceitos relacionados
   - Se o usu√°rio pergunta "como tiro f√©rias?" e voc√™ sabe sobre "solicita√ß√£o de licen√ßas", fa√ßa a conex√£o
   - Sempre tente contextualizar a pergunta em termos que voc√™ conhece

4. CLARIFICA√á√ÉO INTELIGENTE (quando necess√°rio)
   - Use como √öLTIMO RECURSO, nunca como primeira resposta
   - Se realmente n√£o conseguir raciocinar, fa√ßa perguntas que ajudem:
   - Exemplo: "Voc√™ est√° perguntando sobre como solicitar [X], certo? Ou seria sobre [Y]?"
   - Nunca diga "n√£o entendi" - diga "deixa eu confirmar se entendi..."

5. BUSCA NO CORPUS
   - Voc√™ tem acesso a um arquivo de conhecimento sobre SERH
   - SEMPRE use esse arquivo como refer√™ncia principal
   - Se a pergunta n√£o parecer estar l√° imediatamente, procure por:
     - Sin√¥nimos da pergunta
     - Conceitos relacionados
     - T√≥picos gerais que possam conter a resposta

6. CONTEXTUALIZA√á√ÉO
   - Entenda o contexto da pergunta
   - Responda al√©m da pergunta se necess√°rio
   - Ofere√ßa informa√ß√µes complementares √∫teis

7. CONFIDENCIALIDADE E PROFISSIONALISMO
   - Sempre mantenha tom profissional
   - N√£o fa√ßa suposi√ß√µes sobre informa√ß√µes pessoais
   - Seja respeitoso com todos os usu√°rios

=== O QUE FAZER QUANDO N√ÉO TIVER RESPOSTA IMEDIATA ===

1. PROCURE NO ARQUIVO
   - Use a busca para encontrar conte√∫do relacionado
   - Procure por palavras-chave similares
   - Procure por t√≥picos gerais que possam conter a informa√ß√£o

2. RACIONALIZE
   - Conecte conceitos que voc√™ conhece
   - Deduza poss√≠veis respostas baseado em l√≥gica
   - Use contexto hist√≥rico de outras respostas

3. CLARIFIQUE COM O USU√ÅRIO
   - Se mesmo ap√≥s buscar e raciocinar ainda n√£o tiver certeza
   - Fa√ßa perguntas que ajudem a entender melhor a necessidade
   - Ofere√ßa op√ß√µes ou caminhos alternativos
   - Nunca admita falta de conhecimento

=== EXEMPLOS DE RESPOSTAS CORRETAS ===

Pergunta: "O que √© SERH?"
‚ùå ERRADO: "Baseado nos documentos, o SERH √©..."
‚úÖ CORRETO: "O SERH √© o Sistema Eletr√¥nico de Recursos Humanos utilizado pela Justi√ßa Federal, incluindo o TRF4 e outras regi√µes. √â um sistema integrado que auxilia no gerenciamento de recursos humanos, conectado ao SIP para autentica√ß√£o e ao SEI para comunica√ß√£o de processos administrativos."

Pergunta: "Quais s√£o os times?"
‚ùå ERRADO: "Segundo a documenta√ß√£o do SERH, existem 4 times..."
‚úÖ CORRETO: "O SERH possui 4 times principais:
- TIME RED: Liderada por Itamar
- TIME YELLOW: Liderada por Seiji
- TIME BLUE: Liderada por F√°bio
- TIME ORANGE: Liderada por Daniel
Cada time √© respons√°vel por diferentes aspectos da opera√ß√£o."

Pergunta: "Como tiro f√©rias?"
‚ùå ERRADO: "Os documentos indicam que..."
‚úÖ CORRETO: "Para solicitar f√©rias no SERH, voc√™ pode [procedimento]. O processo geralmente envolve [etapas]. Voc√™ quer saber mais sobre prazos ou sobre como acompanhar sua solicita√ß√£o?"

Pergunta amb√≠gua: "Quais s√£o os times?"
‚úÖ CORRETO com clarifica√ß√£o: "Voc√™ est√° perguntando sobre os times que comp√µem a estrutura de desenvolvimento do SERH, ou sobre como organizar times de trabalho dentro da plataforma?"

=== EXEMPLOS AVAN√áADOS: PROCURANDO, RACIONANDO E CLARIFICANDO ===

Pergunta: "Qual √© a pol√≠tica de afastamento?" (palavra diferente de "f√©rias" ou "licen√ßa")
‚ùå ERRADO: "N√£o tenho informa√ß√£o sobre 'afastamento'"
‚úÖ CORRETO: [Procura no corpus por: "afastamento", "licen√ßa", "f√©rias", "aus√™ncia"]
"Entendi que voc√™ quer saber sobre as regras de afastamento. No SERH, temos v√°rios tipos:
- F√©rias: [informa√ß√£o]
- Licen√ßa sa√∫de: [informa√ß√£o]
- Licen√ßa sem vencimento: [informa√ß√£o]
Qual tipo espec√≠fico voc√™ gostaria de saber mais?"

Pergunta: "Como eu fa√ßo para pegar um aumento?" (pergunta sobre "aumento" que pode estar em t√≥picos de "remunera√ß√£o", "sal√°rio", "promo√ß√£o")
‚ùå ERRADO: "N√£o tenho informa√ß√£o sobre aumentos de sal√°rio"
‚úÖ CORRETO: [Busca por: "aumento", "remunera√ß√£o", "sal√°rio", "promo√ß√£o", "carreira"]
"Sobre aumentos salariais no SERH, voc√™ quer saber sobre:
- Aumento por antiguidade/progress√£o funcional?
- B√¥nus ou gratifica√ß√µes?
- Ajustes de IPCA?
Me conte mais para eu dar a informa√ß√£o correta!"

Pergunta: "Qual √© a forma de atesta√ß√£o?" (palavra "atesta√ß√£o" em vez de "atestado")
‚ùå ERRADO: "N√£o encontrei informa√ß√£o sobre 'atesta√ß√£o'"
‚úÖ CORRETO: [Reconhece que "atesta√ß√£o" = submiss√£o/upload de "atestado"]
"Voc√™ quer saber como enviar ou registrar um atestado m√©dico no SERH, certo? O processo √© [procedimento]. Se for algo diferente, me avisa!"

=== T√ìPICOS QUE VOC√ä DOMINA ===
- Defini√ß√£o e fun√ß√£o do SERH
- Estrutura organizacional e times
- Procedimentos: f√©rias, contracheques, atestados, empr√©stimos
- Integra√ß√£o com sistemas (SIP, SEI)
- Pol√≠ticas de RH
- Processos administrativos
- Migra√ß√µes de dados de sistemas legados
- Configura√ß√µes e regras locais

=== QUANDO VOC√ä N√ÉO SABE ===
Se algu√©m perguntar algo fora do escopo do SERH e RH:
"Essa pergunta est√° fora do meu escopo de especializa√ß√£o. Sou especializado em SERH e recursos humanos. Posso ajudar com algo relacionado?"

=== TOM GERAL ===
- Profissional mas amig√°vel
- Confiante (voc√™ sabe o que fala)
- Prestativo e orientado a solu√ß√µes
- Paciente com d√∫vidas
- Sempre dispon√≠vel para ajudar"""
            )
            print(f"‚úì Modelo Gemini pronto")
            return True
        else:
            print("‚úó NENHUM CORPUS ENCONTRADO NO GOOGLE CLOUD")
            print(f"   Verifique:")
            print(f"   - Se PROJECT_ID est√° correto: {PROJECT_ID}")
            print(f"   - Se LOCATION est√° correta: {LOCATION}")
            print(f"   - Se o corpus foi criado no Google Cloud RAG")
            return False
    except Exception as e:
        print(f"‚úó Erro ao inicializar: {e}")
        import traceback
        traceback.print_exc()
        return False


@asynccontextmanager
async def lifespan(app: FastAPI):
    print("iniciando api...")
    init_vertex_ai()
    yield
    print("encerrando api...")


app = FastAPI(lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# Armazena hist√≥rico de conversas em mem√≥ria - CONTROLE MANUAL
# Formato: {conversation_id: [Content(role="user"|"model", parts=[Part(text="...")])]}
conversations = {}


class Message(BaseModel):
    text: str
    conversation_id: Optional[str] = None  # Se None, cria uma nova conversa


class ChatResponse(BaseModel):
    response: str
    conversation_id: str
    corpus: str
    asking_clarification: bool


@app.get("/")
def root():
    return {"api": "rag", "version": "1.0.0", "status": "running"}


@app.get("/health")
def health():
    status = "ok" if model and corpus else "initializing"
    return {"status": status, "corpus": corpus.display_name if corpus else None}


@app.get("/conversation/{conversation_id}")
def get_conversation(conversation_id: str):
    """Retorna hist√≥rico completo de uma conversa"""
    if conversation_id not in conversations:
        return {"error": "conversa n√£o encontrada"}, 404
    
    history = conversations[conversation_id]
    history_formatted = [
        {
            "role": content.role,
            "text": content.parts[0].text if content.parts else ""
        }
        for content in history
    ]
    
    return {
        "conversation_id": conversation_id,
        "history": history_formatted,
        "message_count": len(history)
    }


@app.delete("/conversation/{conversation_id}")
def delete_conversation(conversation_id: str):
    """Deleta uma conversa"""
    if conversation_id not in conversations:
        return {"error": "conversa n√£o encontrada"}, 404
    
    del conversations[conversation_id]
    return {"status": "conversa deletada", "conversation_id": conversation_id}


@app.get("/conversations")
def list_conversations():
    """Lista todas as conversas ativas"""
    return {
        "total_conversations": len(conversations),
        "conversations": [
            {
                "conversation_id": cid,
                "message_count": len(history)
            }
            for cid, history in conversations.items()
        ]
    }


@app.post("/chat")
def chat(msg: Message):
    if not model or not corpus:
        return {"error": "corpus nao carregado"}, 503
    
    if not msg.text.strip():
        return {"error": "mensagem vazia"}, 400
    
    try:
        # Cria ou obt√©m conversa
        conversation_id = msg.conversation_id or str(uuid.uuid4())
        
        if conversation_id not in conversations:
            conversations[conversation_id] = []
        
        history = conversations[conversation_id]
        
        # Constr√≥i conversa completa: hist√≥rico + nova mensagem do usu√°rio
        full_conversation = list(history)
        full_conversation.append(Content(role="user", parts=[Part.from_text(msg.text)]))
        
        # DEBUG DETALHADO
        print(f"\n{'='*70}")
        print(f"üîπ CHAT REQUEST - Conversation ID: {conversation_id}")
        print(f"{'='*70}")
        print(f"üìù Hist√≥rico ANTES: {len(history)} items")
        for i, content in enumerate(history):
            text_preview = content.parts[0].text[:60] if content.parts else ""
            print(f"   [{i}] [{content.role.upper()}]: {text_preview}...")
        
        print(f"\nüì• Nova mensagem: {msg.text}")
        
        print(f"\nüì§ CONVERSA COMPLETA sendo enviada ao modelo ({len(full_conversation)} items):")
        for i, content in enumerate(full_conversation):
            text_preview = content.parts[0].text[:60] if content.parts else ""
            role_display = "USER" if content.role == "user" else "MODEL"
            print(f"   [{i}] [{role_display}]: {text_preview}...")
        
        print(f"\n‚è≥ Aguardando resposta do modelo...")
        print(f"{'='*70}\n")
        
        # Chama modelo COM HIST√ìRICO COMPLETO como primeiro argumento
        response = model.generate_content(
            full_conversation,  # ‚úÖ Passa conversa completa (hist√≥rico + nova msg)
            generation_config={
                "temperature": 0.7,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 1024,
            },
            safety_settings=[
                SafetySetting(
                    category=HarmCategory.HARM_CATEGORY_HARASSMENT,
                    threshold=HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                ),
                SafetySetting(
                    category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                    threshold=HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                ),
                SafetySetting(
                    category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
                    threshold=HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                ),
                SafetySetting(
                    category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                    threshold=HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                ),
            ]
        )
        
        response_text = response.text
        
        # ‚úÖ Salva user message no hist√≥rico
        conversations[conversation_id].append(Content(role="user", parts=[Part.from_text(msg.text)]))
        # ‚úÖ Salva model response no hist√≥rico
        conversations[conversation_id].append(Content(role="model", parts=[Part.from_text(response_text)]))
        
        history = conversations[conversation_id]
        
        # DEBUG
        print(f"{'='*70}")
        print(f"‚úÖ RESPONSE RECEIVED")
        print(f"{'='*70}")
        print(f"üì§ Hist√≥rico DEPOIS: {len(history)} items")
        for i, content in enumerate(history):
            text_preview = content.parts[0].text[:60] if content.parts else ""
            role_display = "USER" if content.role == "user" else "MODEL"
            print(f"   [{i}] [{role_display}]: {text_preview}...")
        
        print(f"\nüìã Resposta do modelo ({len(response_text)} chars):")
        print(f"   {response_text[:100]}...")
        print(f"{'='*70}\n")
        
        # Detecciona se pediu clarifica√ß√£o
        is_asking_clarification = any(keyword in response_text.lower() for keyword in [
            "esclare√ßa", "clarify", "qual √© exatamente", "qual √© o seu", "voc√™ quer dizer",
            "pode ser mais espec√≠fico", "pode detalhar", "qual delas", "qual op√ß√£o",
            "entendo melhor", "como assim", "quer dizer"
        ])
        
        return {
            "response": response_text, 
            "conversation_id": conversation_id,
            "corpus": corpus.display_name,
            "asking_clarification": is_asking_clarification,
            "history_length": len(history)
        }
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"error": str(e)}, 500


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT)

